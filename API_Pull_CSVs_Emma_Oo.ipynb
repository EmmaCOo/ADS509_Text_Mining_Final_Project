{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fmJOn5WURBtRKYAI2ErHDzhzDYlhVBht",
      "authorship_tag": "ABX9TyMjrtwnF8zfiLfTYb6VPg0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmaCOo/ADS509_Text_Mining_Final_Project/blob/main/API_Pull_CSVs_Emma_Oo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**PULL API TWEETS FROM FIVE DIFFERENT BURGER CHAINS**"
      ],
      "metadata": {
        "id": "lV5zGD1UOQTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/twintproject/twint.git@origin/master#egg=twint"
      ],
      "metadata": {
        "id": "1hzhDzw7nBpN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd /content/twint && pip3 install . -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cy0OAOWFl3r",
        "outputId": "2b0465e2-ffdb-4033-c3e1-a4794940fcdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: /content/twint: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkZCKdwEhkaU",
        "outputId": "a1b42c52-ef7a-4f95-a06f-025ef23bc150"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nest_asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: nest-asyncio\n",
            "Successfully installed nest-asyncio-1.5.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**McDONALDS**"
      ],
      "metadata": {
        "id": "ia5IGJ0pN9A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PULL MCDONALD TWEETS SINCE YEAR 2020\n",
        "\n",
        "import twint\n",
        "c = twint.Config()\n",
        "\n",
        "c.Search =  \"\\\"McDonalds\\\"\"    # topic\n",
        "c.Limit = 6000    # number of Tweets to scrape\n",
        "c.Store_csv = True       # store tweets in a csv file\n",
        "c.Since = \"2020-01-01\"\n",
        "c.Lang = \"en\"\n",
        "c.Output = \"mac.csv\"     # path to csv file\n",
        "c.Hide_output = True\n",
        "twint.run.Search(c)"
      ],
      "metadata": {
        "id": "d4wRyXgImBlU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#save as data frame\n",
        "mac = pd.read_csv('mac.csv')\n",
        "mac.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioNOcnQzmK54",
        "outputId": "b2fb9f3e-4369-4d09-8586-3960bfdc3441"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6007, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check any duplicated tweets\n",
        "print((mac.duplicated()).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3E1rET2mSe-",
        "outputId": "71e5ca16-4429-4cce-cc68-a69070312da9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**BURGER KING**"
      ],
      "metadata": {
        "id": "z2KYjhVBN7Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PULL BURGERKING TWEETS SINCE YEAR 2020\n",
        "\n",
        "c = twint.Config()\n",
        "\n",
        "c.Search =  \"\\\"BurgerKing\\\"\"    # topic\n",
        "c.Limit = 6000    # number of Tweets to scrape\n",
        "c.Store_csv = True       # store tweets in a csv file\n",
        "c.Since = \"2020-01-01\"\n",
        "c.Lang = \"en\"\n",
        "c.Output = \"burger.csv\"     # path to csv file\n",
        "c.Hide_output = True\n",
        "twint.run.Search(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUHtC1h-k6G3",
        "outputId": "9936e021-9d36-44e2-a907-abbfd5c56291"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "burger = pd.read_csv('burger.csv')\n",
        "burger.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52x069_3lN4_",
        "outputId": "cc86fc45-0f96-4c4a-97c0-5a97b6c43b17"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5979, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((burger.duplicated()).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbj-MFuNlk0_",
        "outputId": "e123fc49-08ea-430b-f8bf-6be418116786"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**WENDYS**"
      ],
      "metadata": {
        "id": "GxE2P9dQOChi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = twint.Config()\n",
        "\n",
        "c.Search =  \"\\\"Wendys\\\"\"    # topic\n",
        "c.Limit = 5000   # number of Tweets to scrape\n",
        "c.Store_csv = True       # store tweets in a csv file\n",
        "c.Since = \"2022-01-01\"\n",
        "c.Lang = \"en\"\n",
        "c.Output = \"wendys.csv\"     # path to csv file\n",
        "c.Hide_output = True\n",
        "\n",
        "\n",
        "twint.run.Search(c)"
      ],
      "metadata": {
        "id": "VwlKKmcoA9F_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wendys = pd.read_csv('wendys.csv')\n",
        "wendys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waX4H5JaBSkB",
        "outputId": "a36884a6-3a98-43fd-9c60-d4cb8d88bff2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5009, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**JACK IN THE BOX**"
      ],
      "metadata": {
        "id": "dNUlTnu0OGC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = twint.Config()\n",
        "\n",
        "c.Search =  \"\\\"JackBox\\\"\"    # topic\n",
        "c.Limit = 5000   # number of Tweets to scrape\n",
        "c.Store_csv = True       # store tweets in a csv file\n",
        "c.Since = \"2022-01-01\"\n",
        "c.Lang = \"en\"\n",
        "c.Output = \"jackbox.csv\"     # path to csv file\n",
        "c.Hide_output = True\n",
        "\n",
        "\n",
        "twint.run.Search(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAoP5n-CIRUq",
        "outputId": "7c013389-2f15-4025-fb8e-6fa6bb2a3bb9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[!] No more data! Scraping will stop now.\n",
            "found 0 deleted tweets in this search.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jackbox = pd.read_csv('jackbox.csv')\n",
        "jackbox.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0xovSoVIYxQ",
        "outputId": "a5de9175-419a-4606-fed0-7fff7c858dd7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4506, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**CHICK-FIL-A**"
      ],
      "metadata": {
        "id": "8vDJ6AutOIoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = twint.Config()\n",
        "\n",
        "c.Search =  \"\\\"ChickfilA\\\"\"    # topic\n",
        "c.Limit = 5000   # number of Tweets to scrape\n",
        "c.Store_csv = True       # store tweets in a csv file\n",
        "c.Since = \"2022-01-01\"\n",
        "c.Lang = \"en\"\n",
        "c.Output = \"chick.csv\"     # path to csv file\n",
        "c.Hide_output = True\n",
        "\n",
        "\n",
        "twint.run.Search(c)"
      ],
      "metadata": {
        "id": "e6eUu8KcJ5hq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chick = pd.read_csv('chick.csv')\n",
        "chick.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugm00hAWKIfR",
        "outputId": "1735a169-1cfe-4507-98fa-c918389631cc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5016, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}